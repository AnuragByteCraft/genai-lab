{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93f4bf3-cab9-4556-8b5f-071150882bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from get_llm import get_llm  # Wrapper for LangChain around OpenAI API, uses LM Studio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c7263-9399-44fb-8875-0df6e1f4c19f",
   "metadata": {},
   "source": [
    "## Chatbot Implementation - Illustration of basic idea of chat history\n",
    "## Make sure LM Studio runs and suitable model is loaded\n",
    "## This is a simple demo and can be done with about < 1K token context size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc68112-94f6-4904-adc2-154e9e49ec70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019BD8945050>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019BD8E80B10>, root_client=<openai.OpenAI object at 0x0000019BD8944510>, root_async_client=<openai.AsyncOpenAI object at 0x0000019BD8E80790>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://localhost:1234/v1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_llm()  # Wrapper for LangChain around OpenAI API\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a973da-9b82-499e-8ccd-3bd7ef6abf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Hi I am Ananth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Ananth! It's lovely to meet you. ðŸ˜Š \n",
      "\n",
      "I'm here to help with whatever you need. Just let me know what's on your mind! What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "query = input(\"User: \")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful, friendly assistant\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "    },\n",
    "]\n",
    "response1 = model.invoke(messages)  # model.invoke([HumanMessage(content=\"What's my name?\")])\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194a7d15-4926-4a12-95d2-2dfb42e5fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't know your name! You haven't told me yet. ðŸ˜Š \n",
      "\n",
      "Feel free to tell me your name if you'd like â€“ it would be nice to address you properly!\n",
      "\n",
      "\n",
      "\n",
      "What's your name?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful, friendly assistant\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "    },\n",
    "]\n",
    "response1 = model.invoke(messages)  # model.invoke([HumanMessage(content=\"What's my name?\")])\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae66fbad-414b-49ae-9e65-6917849de413",
   "metadata": {},
   "source": [
    "### Note from the above that the model doesn't remember a previous context, we need to pass explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80152df5-9b9d-4358-bd25-7a6a0b15e5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ananth. ðŸ˜Š You told me that yourself!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Ananth\"),\n",
    "        AIMessage(content=\"Hello Ananth! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccdb5276-494e-4b86-93fb-aaf09aeb8dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Ananth! The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Ananth\"),\n",
    "        AIMessage(content=\"Hello Ananth! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "        AIMessage(content='Your name is Ananth!'),\n",
    "        HumanMessage(content=\"Address me by my name and answer: What is the capital of India?\"),\n",
    "        \n",
    "    ]\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46418552-2498-4a44-aa34-8e56d45c3578",
   "metadata": {},
   "source": [
    "### Basic Idea: When we pass history explicitly the model can remember the context - so keep a small memory and pass everytime to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9220393d-6ed9-4095-9851-d742feeacc72",
   "metadata": {},
   "source": [
    "## Message History\n",
    "\n",
    "### We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a4b588-430c-403a-98cf-549a7571615b",
   "metadata": {},
   "source": [
    "### We may also want to support multiple sessions. So we can define a session id and use it to identify the session.\n",
    "### We need to get a reference to a message history object for the given session\n",
    "### Write a function get_session_history that takes a session id and returns a message history \n",
    "### Also define RunnableWithMessageHistory with parameters model and get_session_history function\n",
    "###  This session_id is used to distinguish between separate conversations, and should be passed in as part of the config when calling the new chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4267aec3-d085-4f57-93d7-943ff0b64895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}  # maps a session id to a history object\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24545d62-9291-4d3f-898c-1d56bd302a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7087d4d9-4b15-4292-829d-4a876a696a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Ananth! It's great to meet you. ðŸ˜Š \\n\\nWhat can I do for you today? Do you have any questions, need help with something, or just want to chat?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Ananth\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038efa3e-6014-4e01-a466-0fbfd680b3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Ananth! You told me that when we first started chatting. ðŸ˜„\\n\\n\\n\\nIt's a pleasure to be talking with you, Ananth.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bacaeb-5a3e-451b-ad74-3a69d1cfd7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't know your name. You haven't told me! ðŸ˜Š \\n\\nYou can tell me if you like.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518570ad-5fb3-4e7a-a0bc-97ab4682291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You know what? You are absolutely right to ask again! My apologies. I seem to be having a little trouble remembering. \\n\\nYour name is **Ananth**.\\n\\n\\n\\nI am still under development and learning to remember things better. Thanks for pointing out my mistake!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9104e2-18ca-4af8-9b4d-45bf7b57e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Who is the founder of Adobe?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a71b8-a10d-421e-973c-2db9f561044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Does it make Photoshop?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365faada-474a-4077-831a-5b5eeb540db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
